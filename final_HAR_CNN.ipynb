{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import necessary libraries for data processing, modeling, and evaluation\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import classification_report, confusion_matrix\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Input\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam"],"metadata":{"id":"_TtrMrnrIGDO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mount Google Drive to access the dataset stored in Google Drive (for Google Colab)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load the training and testing data\n","train_data = pd.read_csv('/content/drive/My Drive/archive/train.csv')\n","test_data = pd.read_csv('/content/drive/My Drive/archive/test.csv')"],"metadata":{"id":"wVdr8DD4IIm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract features and labels from the training and testing data\n","X_train = train_data.drop(columns=['Activity'])\n","y_train = train_data['Activity']\n","X_test = test_data.drop(columns=['Activity'])\n","y_test = test_data['Activity']"],"metadata":{"id":"imR122OYINNH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Map the activity labels to numerical values\n","activity_mapping = {'LAYING': 0, 'WALKING': 1, 'WALKING_UPSTAIRS': 2,\n","                    'WALKING_DOWNSTAIRS': 3, 'SITTING': 4, 'STANDING': 5}\n","y_train = y_train.map(activity_mapping)\n","y_test = y_test.map(activity_mapping)"],"metadata":{"id":"Nh21xxkUIQj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert activity labels to categorical (one-hot encoding)\n","y_train = to_categorical(y_train, num_classes=6)\n","y_test = to_categorical(y_test, num_classes=6)"],"metadata":{"id":"5a9TooT_IX7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reshape input data for Conv1D (adding a channel dimension)\n","X_train = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_test = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n"],"metadata":{"id":"CPNGhFZUIbKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the CNN model architecture with Conv1D layers\n","def build_cnn_model():\n","    model = Sequential([\n","        Input(shape=(X_train.shape[1], 1)),  # Input layer\n","        Conv1D(64, kernel_size=3, activation='relu'),  # First Conv Layer\n","        BatchNormalization(),  # BatchNormalization after Conv Layer\n","        MaxPooling1D(pool_size=2),  # MaxPooling layer\n","        Dropout(0.3),  # Dropout for regularization\n","\n","        Conv1D(128, kernel_size=3, activation='relu'),  # Second Conv Layer\n","        BatchNormalization(),\n","        MaxPooling1D(pool_size=2),\n","        Dropout(0.4),\n","\n","        Conv1D(256, kernel_size=3, activation='relu'),  # Third Conv Layer\n","        BatchNormalization(),\n","        MaxPooling1D(pool_size=2),\n","\n","        Flatten(),  # Flatten the output for Dense layers\n","        Dense(128, activation='relu'),  # Fully connected layer\n","        Dropout(0.5),  # Dropout for regularization\n","        Dense(6, activation='softmax')  # Output layer with 6 classes (activities)\n","    ])\n","    return model\n"],"metadata":{"id":"amVZBJvUIlG_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize parameters and lists to store models and accuracies\n","num_models = 3\n","models = []\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","cnn_fold_accuracies = []\n","history_dict = {}"],"metadata":{"id":"CD6lOvmOIq4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loop over to train multiple CNN models\n","for i in range(num_models):\n","    print(f\"\\nTraining CNN Model {i+1}\")\n","    cnn_model = build_cnn_model()  # Build the CNN model\n","    cnn_model.compile(optimizer=Adam(learning_rate=0.001),  # Compile the model with Adam optimizer\n","                      loss='categorical_crossentropy',  # Loss function for multi-class classification\n","                      metrics=['accuracy'])  # Track accuracy during training\n","\n","    # Perform K-Fold Cross-Validation\n","    for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n","        print(f\"\\nCNN Model {i+1}, Fold {fold + 1}\")\n","        X_tr, X_val = X_train[train_index], X_train[val_index]\n","        y_tr, y_val = y_train[train_index], y_train[val_index]\n","\n","        # Early stopping and learning rate reduction callbacks\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-5)\n","\n","        # Train the model on the current fold\n","        history = cnn_model.fit(X_tr, y_tr, validation_data=(X_val, y_val),\n","                                epochs=30, batch_size=32,\n","                                callbacks=[early_stopping, reduce_lr])\n","\n","        # Evaluate the model on the validation data\n","        val_loss, val_accuracy = cnn_model.evaluate(X_val, y_val, verbose=0)\n","        cnn_fold_accuracies.append(val_accuracy)\n","        print(f\"Model {i+1}, Fold Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    models.append(cnn_model)  # Add the trained model to the models list\n"],"metadata":{"id":"1ZZiANQMItyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to predict with an ensemble of models by averaging their predictions\n","def model_ensemble_predict(models, X):\n","    # Get predictions from each model and average them\n","    predictions = [model.predict(X) for model in models]\n","    averaged_predictions = np.mean(predictions, axis=0)  # Average across all models\n","    return averaged_predictions"],"metadata":{"id":"dbM_jzHyI16M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate ensemble model on the test set\n","ensemble_predictions = model_ensemble_predict(models, X_test)"],"metadata":{"id":"XSBfRjcKI7dP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate test accuracy of the ensemble model\n","ensemble_test_accuracy = np.mean(np.argmax(ensemble_predictions, axis=1) == np.argmax(y_test, axis=1))\n","print(f\"Ensemble Test Accuracy: {ensemble_test_accuracy:.4f}\")"],"metadata":{"id":"2pQKMjRrI9XC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate on Test Set using Ensemble\n","ensemble_predictions = model_ensemble_predict(models, X_test)\n","ensemble_test_accuracy = np.mean(np.argmax(ensemble_predictions, axis=1) == np.argmax(y_test, axis=1))\n","print(f\"Ensemble Test Accuracy: {ensemble_test_accuracy:.4f}\")"],"metadata":{"id":"xrMd96FdJYpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classification Report for Ensemble\n","print(\"\\nClassification Report for Ensemble:\")\n","print(classification_report(y_true, y_pred_ensemble, target_names=activity_mapping.keys()))"],"metadata":{"id":"hLNEDJYQ6pqM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Confusion Matrix for Ensemble\n","y_pred_ensemble = ensemble_predictions.argmax(axis=1)\n","y_true = y_test.argmax(axis=1)\n","cm_ensemble = confusion_matrix(y_true, y_pred_ensemble)\n"],"metadata":{"id":"fQoP7-GrIFK4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot Confusion Matrix for Ensemble\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(cm_ensemble, annot=True, fmt='d', cmap='Blues', xticklabels=activity_mapping.keys(), yticklabels=activity_mapping.keys())\n","plt.title('Ensemble Confusion Matrix')\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.show()"],"metadata":{"id":"uE_TvWDd6z4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Assuming you have 'cnn_fold_accuracies' from your original code\n","\n","# Reshape accuracies to (num_models, num_folds)\n","num_folds = 5  # Number of folds in KFold\n","cnn_fold_accuracies_reshaped = np.array(cnn_fold_accuracies).reshape(num_models, num_folds)\n","\n","# Calculate mean and standard deviation across folds for each model\n","mean_accuracies = np.mean(cnn_fold_accuracies_reshaped, axis=1)\n","std_accuracies = np.std(cnn_fold_accuracies_reshaped, axis=1)\n","\n","# Plotting Accuracy across Folds for Each Model\n","plt.figure(figsize=(10, 6))\n","for i in range(num_models):\n","    plt.plot(range(1, num_folds + 1), cnn_fold_accuracies_reshaped[i], label=f\"Model {i + 1}\")\n","    plt.errorbar(range(1, num_folds + 1), cnn_fold_accuracies_reshaped[i], yerr=std_accuracies[i], fmt='o', capsize=5)\n","\n","plt.title(\"Accuracy across Folds for Each Model in Ensemble\")\n","plt.xlabel(\"Fold\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"IJMDDw6Z7IBl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Bs0jQjjw6LvF"},"execution_count":null,"outputs":[]}]}